{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install optimum-quanto\n#restart kernal after installing\nfrom IPython.core.display import HTML\nHTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"9X-j3fR9ytxU","outputId":"7b33859b-c33e-400b-dbd0-bb207ce70ec8","execution":{"iopub.status.busy":"2024-07-31T15:28:35.957846Z","iopub.execute_input":"2024-07-31T15:28:35.958209Z","iopub.status.idle":"2024-07-31T15:28:48.278497Z","shell.execute_reply.started":"2024-07-31T15:28:35.958177Z","shell.execute_reply":"2024-07-31T15:28:48.277398Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: optimum-quanto in /opt/conda/lib/python3.10/site-packages (0.2.4)\nRequirement already satisfied: torch>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from optimum-quanto) (2.4.0)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from optimum-quanto) (1.11.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum-quanto) (1.26.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from optimum-quanto) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (2024.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->optimum-quanto) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->optimum-quanto) (12.5.82)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.4.0->optimum-quanto) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.4.0->optimum-quanto) (1.3.0)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<script>Jupyter.notebook.kernel.restart()</script>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install torch-pruning\nimport torch_pruning as tp\nfrom optimum.quanto import Calibration, QTensor, freeze, qfloat8, qint4, qint8, qint2,quantize","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CerBVQCoytxX","outputId":"a8b141e1-0e59-46bc-e590-c620923bb078","execution":{"iopub.status.busy":"2024-07-31T15:28:48.280819Z","iopub.execute_input":"2024-07-31T15:28:48.281284Z","iopub.status.idle":"2024-07-31T15:29:00.507628Z","shell.execute_reply.started":"2024-07-31T15:28:48.281245Z","shell.execute_reply":"2024-07-31T15:29:00.506510Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch-pruning in /opt/conda/lib/python3.10/site-packages (1.4.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torch-pruning) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-pruning) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (2024.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torch-pruning) (12.5.82)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torch-pruning) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torch-pruning) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model(model,\n                train_loader,\n                test_loader,\n                device,\n                learning_rate=1e-1,\n                num_epochs=200):\n\n    criterion = nn.CrossEntropyLoss()\n\n    model.to(device)\n\n    optimizer = optim.SGD(model.parameters(),\n                          lr=learning_rate,\n                          momentum=0.9,\n                          weight_decay=1e-4)\n\n    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n                                                     milestones=[100, 150],\n                                                     gamma=0.1,\n                                                     last_epoch=-1)\n\n    # Evaluation\n    model.eval()\n    eval_loss, eval_accuracy = evaluate_model(model=model,\n                                              test_loader=test_loader,\n                                              device=device,\n                                              criterion=criterion)\n    print(\"Epoch: {:03d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(\n        0, eval_loss, eval_accuracy))\n\n    for epoch in range(num_epochs):\n\n        # Training\n        model.train()\n\n        running_loss = 0\n        running_corrects = 0\n\n        for inputs, labels in train_loader:\n\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # statistics\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        train_loss = running_loss / len(train_loader.dataset)\n        train_accuracy = running_corrects / len(train_loader.dataset)\n\n        # Evaluation\n        model.eval()\n        eval_loss, eval_accuracy = evaluate_model(model=model,\n                                                  test_loader=test_loader,\n                                                  device=device,\n                                                  criterion=criterion)\n\n        scheduler.step()\n\n        print(\n            \"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\"\n            .format(epoch + 1, train_loss, train_accuracy, eval_loss,\n                    eval_accuracy))\n\n    return model\n\ndef evaluate_model(model, test_loader, device, criterion=None):\n\n    model.eval()\n    model.to(device)\n\n    running_loss = 0\n    running_corrects = 0\n\n    for inputs, labels in test_loader:\n\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        if criterion is not None:\n            loss = criterion(outputs, labels).item()\n        else:\n            loss = 0\n\n        # statistics\n        running_loss += loss * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\n    eval_loss = running_loss / len(test_loader.dataset)\n    eval_accuracy = running_corrects / len(test_loader.dataset)\n\n    return eval_loss, eval_accuracy\n","metadata":{"id":"Q9I7QqBvytxX","execution":{"iopub.status.busy":"2024-07-31T15:43:04.719680Z","iopub.execute_input":"2024-07-31T15:43:04.720045Z","iopub.status.idle":"2024-07-31T15:43:04.737074Z","shell.execute_reply.started":"2024-07-31T15:43:04.720017Z","shell.execute_reply":"2024-07-31T15:43:04.736130Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def save_model(model, model_dir, model_filename):\n\n    if not os.path.exists(model_dir):\n        os.makedirs(model_dir)\n    model_filepath = os.path.join(model_dir, model_filename)\n    torch.save(model.state_dict(), model_filepath)\n\ndef load_model(model, model_filepath, device):\n\n    model.load_state_dict(torch.load(model_filepath, map_location=device))\n\n    return model","metadata":{"id":"9OskFFOfytxY","execution":{"iopub.status.busy":"2024-07-31T15:43:05.515169Z","iopub.execute_input":"2024-07-31T15:43:05.516010Z","iopub.status.idle":"2024-07-31T15:43:05.521758Z","shell.execute_reply.started":"2024-07-31T15:43:05.515977Z","shell.execute_reply":"2024-07-31T15:43:05.520661Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision import models\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Transformation for MobileNet\ntransform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),  # Convert grayscale images to 3 channels\n    transforms.Resize((32, 32)),  \n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # Standard normalization for ImageNet\n])\n\nbatch_size = 128\n\n# MNIST dataset\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n\n# Data loaders\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"id":"DrwuW06vytxY","execution":{"iopub.status.busy":"2024-07-31T15:43:06.315650Z","iopub.execute_input":"2024-07-31T15:43:06.316324Z","iopub.status.idle":"2024-07-31T15:43:06.405450Z","shell.execute_reply.started":"2024-07-31T15:43:06.316293Z","shell.execute_reply":"2024-07-31T15:43:06.404421Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\nimport time\ndef test(model, device, test_loader):\n    model.to(device)\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        start = time.time()\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            if isinstance(output, QTensor):\n                output = output.dequantize()\n            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n        end = time.time()\n\n    test_loss /= len(test_loader.dataset)\n\n    print(\n        \"\\nTest set evaluated in {:.2f} s: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n            end - start, test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n        )\n    )","metadata":{"id":"LzPVrL3UytxZ","execution":{"iopub.status.busy":"2024-07-31T15:43:07.818594Z","iopub.execute_input":"2024-07-31T15:43:07.819259Z","iopub.status.idle":"2024-07-31T15:43:07.827640Z","shell.execute_reply.started":"2024-07-31T15:43:07.819228Z","shell.execute_reply":"2024-07-31T15:43:07.826717Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Load pretrained MobileNet model\nmodel = models.mobilenet_v2(pretrained=True)\n\n# Modify the classifier to match the number of classes in MNIST (10 classes)\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)\n\n# Move model to the device (GPU or CPU)\nmodel = model.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training function\ndef train_models(model, train_loader, test_loader, device, criterion, optimizer, num_epochs=1):\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        for i, (images, labels) in enumerate(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n        # Evaluate the model\n        model.eval()\n        with torch.no_grad():\n            correct = 0\n            total = 0\n            for images, labels in test_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        print(f'Accuracy of the model on the test images: {100 * correct / total} %')\n\n# Train and evaluate the model\ntrain_models(model=model,\n            train_loader=train_loader,\n            test_loader=test_loader,\n            device=device,\n            criterion=criterion,\n            optimizer=optimizer,\n            num_epochs=1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xI77kDEZytxZ","outputId":"af0dabd3-424d-454f-f20d-3290f4215906","execution":{"iopub.status.busy":"2024-07-31T15:47:30.716007Z","iopub.execute_input":"2024-07-31T15:47:30.716621Z","iopub.status.idle":"2024-07-31T15:48:13.764048Z","shell.execute_reply.started":"2024-07-31T15:47:30.716591Z","shell.execute_reply":"2024-07-31T15:48:13.763124Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Epoch [1/1], Loss: 0.1253\nAccuracy of the model on the test images: 98.55 %\n","output_type":"stream"}]},{"cell_type":"code","source":"test(model, device, test_loader)\n\nmodel_dir = \"/kaggle/working/\"\nmodel_filename = \"Mobilenet_v2.pth\"\nmodel_filepath = model_dir + model_filename\nimport os\n#save_model(model=model, model_dir=model_dir, model_filename=model_filename)\ntorch.save(model,model_filepath)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0BCFuYjytxZ","outputId":"a4b9dddf-5f9d-4e73-9d7f-dff1f90ff531","execution":{"iopub.status.busy":"2024-07-31T15:48:13.766004Z","iopub.execute_input":"2024-07-31T15:48:13.766447Z","iopub.status.idle":"2024-07-31T15:48:18.553080Z","shell.execute_reply.started":"2024-07-31T15:48:13.766413Z","shell.execute_reply":"2024-07-31T15:48:18.552115Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"\nTest set evaluated in 4.71 s: Average loss: -10.6797, Accuracy: 9855/10000 (99%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#new_model = torch.load(model_filepath)\n#test(new_model, device, test_loader)","metadata":{"id":"5ah85i504ZoC","execution":{"iopub.status.busy":"2024-07-31T15:48:18.554371Z","iopub.execute_input":"2024-07-31T15:48:18.554642Z","iopub.status.idle":"2024-07-31T15:48:18.558619Z","shell.execute_reply.started":"2024-07-31T15:48:18.554619Z","shell.execute_reply":"2024-07-31T15:48:18.557667Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"all_images = []\ntargets = []\n\nfor image, target in test_loader:\n    all_images.append(image)\n    targets.append(target)\n    break\n# Concatenate all the images into a single tensor\nall_images_tensor = torch.cat(all_images, dim=0)\ntargets_tensor = torch.cat(all_images, dim=0)\nprint(all_images_tensor.shape)\nprint(targets_tensor.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vO6GoRR2ytxa","outputId":"4d367891-2273-4076-ff48-bdbb383f03d4","execution":{"iopub.status.busy":"2024-07-31T15:48:18.560662Z","iopub.execute_input":"2024-07-31T15:48:18.561000Z","iopub.status.idle":"2024-07-31T15:48:18.622602Z","shell.execute_reply.started":"2024-07-31T15:48:18.560975Z","shell.execute_reply":"2024-07-31T15:48:18.621700Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"torch.Size([128, 3, 32, 32])\ntorch.Size([128, 3, 32, 32])\n","output_type":"stream"}]},{"cell_type":"code","source":"# for name,m in new_model.named_modules():\n#     print(name)","metadata":{"id":"ZRUJ2Bo68BOd","execution":{"iopub.status.busy":"2024-07-31T15:48:18.623783Z","iopub.execute_input":"2024-07-31T15:48:18.624121Z","iopub.status.idle":"2024-07-31T15:48:18.629037Z","shell.execute_reply.started":"2024-07-31T15:48:18.624090Z","shell.execute_reply":"2024-07-31T15:48:18.628132Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# example_inputs = torch.randn(1,3,224,224).to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\nexample_inputs = all_images_tensor.clone().detach().requires_grad_(True).to(device)\neample_targets = targets_tensor.clone().detach().requires_grad_(True).to(device)\n\n# 1. Importance criterion\nimp = tp.importance.GroupTaylorImportance() # or GroupNormImportance(p=2), GroupHessianImportance(), etc.\n\n# 2. Initialize a pruner with the model and the importance criterion\nignored_layers = [model.features[1], model.features[2], model.features[3], model.features[4]]\nfor m in model.modules():\n    if isinstance(m, torch.nn.Linear) and m.out_features == 10:\n        ignored_layers.append(m) # DO NOT prune the final classifier!\n\npruning_ratio_dict = {\n#     model.features[1]: 0.2,\n#     model.features[3]: 0.3,\n#     model.features[6]: 0.4,\n#     model.features[13]: 0.5,\n    model.classifier: 0.2 # Example: Pruning 20% of the channels in the classifier\n}\n\npruner1 = tp.pruner.MetaPruner( # We can always choose MetaPruner if sparse training is not required.\n    model,\n    example_inputs,\n    importance=imp,\n    pruning_ratio=0.2, \n    # pruning_ratio_dict =pruning_ratio_dict , # customized pruning ratios for layers or blocks\n    ignored_layers=ignored_layers,\n)\n# pruner2 = tp.pruner.MetaPruner( # We can always choose MetaPruner if sparse training is not required.\n#     model,\n#     example_inputs,\n#     importance=imp,\n#     # pruning_ratio=0.1, \n#     pruning_ratio_dict =pruning_ratio_dict , # customized pruning ratios for layers or blocks\n#     ignored_layers=ignored_layers,\n# )\n\n# 3. Prune & finetune the model\nbase_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\nif isinstance(imp, tp.importance.GroupTaylorImportance):\n    # Taylor expansion requires gradients for importance estimation\n#     loss = new_model(example_inputs).sum() # A dummy loss, please replace this line with your loss function and data!\n    loss = criterion(example_inputs,eample_targets)\n    loss.backward() # before pruner.step()","metadata":{"id":"e88kk6jWytxa","execution":{"iopub.status.busy":"2024-07-31T15:48:18.630008Z","iopub.execute_input":"2024-07-31T15:48:18.630263Z","iopub.status.idle":"2024-07-31T15:48:18.746478Z","shell.execute_reply.started":"2024-07-31T15:48:18.630242Z","shell.execute_reply":"2024-07-31T15:48:18.745522Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"pruner1.step()\n\nmacs, nparams = tp.utils.count_ops_and_params(model.to(device), example_inputs.to(device))\nprint(\n    \" Params: %.2f M => %.2f M\"\n    % (base_nparams / 1e6, nparams / 1e6)\n)\n\n# pruner2.step()\n\n# macs, nparams = tp.utils.count_ops_and_params(model.to(device), example_inputs.to(device))\n# print(\n#     \" Params: %.2f M => %.2f M\"\n#     % (base_nparams / 1e6, nparams / 1e6)\n# )\n\n\ntest(model, device, test_loader)\n\ntorch.save(model,\"/kaggle/working/pruned.pth\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFrceArlytxb","outputId":"9be44f89-faab-458a-e1ec-7ad23b1af23f","execution":{"iopub.status.busy":"2024-07-31T15:48:18.747738Z","iopub.execute_input":"2024-07-31T15:48:18.748039Z","iopub.status.idle":"2024-07-31T15:48:23.649249Z","shell.execute_reply.started":"2024-07-31T15:48:18.748013Z","shell.execute_reply":"2024-07-31T15:48:23.648256Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":" Params: 2.24 M => 1.46 M\n Params: 2.24 M => 1.46 M\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch_pruning/pruner/algorithms/metapruner.py:385: UserWarning: Pruning exceed the maximum iterative steps, no pruning will be performed.\n  warnings.warn(\"Pruning exceed the maximum iterative steps, no pruning will be performed.\")\n","output_type":"stream"},{"name":"stdout","text":"\nTest set evaluated in 4.53 s: Average loss: -1.4228, Accuracy: 5195/10000 (52%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def Quantize(model,weights_dtype,activations_dtype):\n    quantize(model, weights=weights_dtype, activations=activations_dtype)\n    print(\"Calibrating ...\")\n    with Calibration():\n        test(model, device, test_loader)\n    freeze(model)\n\nweights = [qint8,qint4,qint2,qfloat8]\nstrs = [\"int8.pth\",\"int4.pth\",\"int2.pth\",\"float8.pth\"]\nactivations = [qint8,qint4,qint2,qfloat8]\n\ni= 0#change here\n# pruned_model = torch.load(\"/content/drive/MyDrive/vision lab/Mobilenet_v2.pth\")\nQuantize(model = model,weights_dtype=weights[i],activations_dtype=activations[i])\npath = \"/kaggle/working/\"+strs[i]\ntorch.save(model,path)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VMxYVQHnytxb","outputId":"bd9cbe0f-b7b7-42c5-8864-63ec58d685cb","execution":{"iopub.status.busy":"2024-07-31T15:49:22.716040Z","iopub.execute_input":"2024-07-31T15:49:22.716658Z","iopub.status.idle":"2024-07-31T15:49:34.074138Z","shell.execute_reply.started":"2024-07-31T15:49:22.716627Z","shell.execute_reply":"2024-07-31T15:49:34.073265Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Calibrating ...\n\nTest set evaluated in 11.22 s: Average loss: -1.4271, Accuracy: 5176/10000 (52%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"if i==0:\n    ptq_model = torch.load(\"/kaggle/working/int8.pth\")\n    print(\"int8 model:\")\n    test(ptq_model, device, test_loader)\nelif i==1:\n    ptq_model = torch.load(\"/kaggle/working/int4.pth\")\n    print(\"int4 model:\")\n    test(ptq_model, device, test_loader)\nelif i==2:\n    ptq_model = torch.load(\"/kaggle/working/int2.pth\")\n    print(\"int2 model:\")\n    test(ptq_model, device, test_loader)\nelse:\n    ptq_model = torch.load(\"/kaggle/working/float8.pth\")\n    print(\"float8 model:\")\n    test(ptq_model, device, test_loader)","metadata":{"id":"qRShkgemytxb","outputId":"f404dc29-e3c6-4ebb-a30c-207de6b281ab","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-07-31T15:49:34.075913Z","iopub.execute_input":"2024-07-31T15:49:34.076225Z","iopub.status.idle":"2024-07-31T15:49:39.797939Z","shell.execute_reply.started":"2024-07-31T15:49:34.076201Z","shell.execute_reply":"2024-07-31T15:49:39.796999Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"int8 model:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/2039530220.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ptq_model = torch.load(\"/kaggle/working/int8.pth\")\n","output_type":"stream"},{"name":"stdout","text":"\nTest set evaluated in 5.62 s: Average loss: -1.4291, Accuracy: 5173/10000 (52%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# for name, param in ptq_model.named_parameters():\n#     print(name)\n#     print(param)\n#     break","metadata":{"id":"NEZUX71Wytxc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **QAT for model(optional)**","metadata":{"id":"8ehQ5y51ytxc"}},{"cell_type":"code","source":"# quantize(ptq_model,weights=qint4,activations=qint4)\nqat_model = train_model(model=ptq_model,\n            train_loader=train_loader,\n            test_loader=test_loader,\n            device=device,\n            num_epochs=2)\n\ntest(ptq_model, device, test_loader)\n\nfreeze(qat_model)\nprint(\"after freezing:\")\ntest(qat_model, device, test_loader)\ntorch.save(qat_model,path)","metadata":{"id":"P49GLQdWytxd","outputId":"2cc91a7c-b892-417e-b0ef-6f747a6bfcc8","colab":{"base_uri":"https://localhost:8080/","height":402},"execution":{"iopub.status.busy":"2024-07-31T15:50:17.824748Z","iopub.execute_input":"2024-07-31T15:50:17.825646Z","iopub.status.idle":"2024-07-31T15:52:45.289719Z","shell.execute_reply.started":"2024-07-31T15:50:17.825607Z","shell.execute_reply":"2024-07-31T15:52:45.288862Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Epoch: 000 Eval Loss: 1.526 Eval Acc: 0.517\nEpoch: 001 Train Loss: 0.061 Train Acc: 0.982 Eval Loss: 0.045 Eval Acc: 0.985\nEpoch: 002 Train Loss: 0.045 Train Acc: 0.987 Eval Loss: 0.036 Eval Acc: 0.989\n\nTest set evaluated in 5.54 s: Average loss: -7.5813, Accuracy: 9895/10000 (99%)\n\nafter freezing:\n\nTest set evaluated in 5.55 s: Average loss: -7.5813, Accuracy: 9895/10000 (99%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"for name, param in qat_model.named_parameters():\n    print(name)\n    print(param)\n    break","metadata":{"id":"5gqjJZSuytxd","outputId":"8edec1ae-472b-44e8-dc45-1b4a5648eb52","execution":{"iopub.status.busy":"2024-07-31T15:53:12.825216Z","iopub.execute_input":"2024-07-31T15:53:12.825918Z","iopub.status.idle":"2024-07-31T15:53:12.882193Z","shell.execute_reply.started":"2024-07-31T15:53:12.825888Z","shell.execute_reply":"2024-07-31T15:53:12.881362Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"features.0.0.weight\nQBytesTensor(tensor([[[[  45,  -15,   50],\n          [ 111,  -86,   23],\n          [  36, -127,  -50]],\n\n         [[  27,  -20,   51],\n          [  68, -112,   -7],\n          [  39, -112,  -27]],\n\n         [[ -86,  -69,  -34],\n          [ -38, -100,  -52],\n          [ -90, -114,  -82]]],\n\n\n        [[[  -9,   -2,    6],\n          [  24,   64,    7],\n          [ -32,  -47,   -8]],\n\n         [[ -10,   11,    2],\n          [  47,  127,   17],\n          [ -57, -103,  -15]],\n\n         [[  -1,    0,    7],\n          [   9,   29,    0],\n          [ -11,  -26,   -2]]],\n\n\n        [[[ -11,    8,   -1],\n          [ -36,   63,  -27],\n          [ -60,   79,  -25]],\n\n         [[ -12,   16,   -4],\n          [ -72,  115,  -46],\n          [ -94,  127,  -40]],\n\n         [[  -3,   -3,    2],\n          [ -18,   32,  -15],\n          [ -26,   37,  -13]]],\n\n\n        [[[   1,   -6,   16],\n          [  11,   37,  -52],\n          [   3,   57,  -60]],\n\n         [[  -1,  -10,   16],\n          [   8,   95, -112],\n          [   9,  118, -127]],\n\n         [[  -2,   -3,    5],\n          [   8,   16,  -13],\n          [   0,   17,  -22]]],\n\n\n        [[[ -16,    8,    9],\n          [  -2,  -18,  -17],\n          [  22,  -28,  -79]],\n\n         [[   5,   11,    0],\n          [  13,  -48,  -60],\n          [  43,  -53, -127]],\n\n         [[  -1,    8,   -5],\n          [  -6,  -13,  -14],\n          [   1,  -16,  -32]]],\n\n\n        [[[  30,   32,  -46],\n          [  24,  124,   49],\n          [ -29,  118,  127]],\n\n         [[   2,  -25,    0],\n          [  -6,  -44,  -25],\n          [  -3,  -36,  -26]],\n\n         [[ -27,  -11,   44],\n          [  -7,  -72,  -20],\n          [  33,  -72,  -88]]],\n\n\n        [[[  -3,   -3,    0],\n          [  62,  -19,  -31],\n          [  17,  -16,  -13]],\n\n         [[  -9,   -2,    3],\n          [ 127,  -38,  -66],\n          [  35,  -33,  -15]],\n\n         [[   1,    1,    0],\n          [  31,   -9,  -18],\n          [   8,   -6,   -5]]],\n\n\n        [[[   5,   -8,  -26],\n          [  -2,   13,   48],\n          [   1,   29,   79]],\n\n         [[  -4,  -24,  -40],\n          [   3,   35,   80],\n          [   5,   71,  127]],\n\n         [[  -2,   -8,   -9],\n          [   2,   -2,   24],\n          [   8,   13,   30]]],\n\n\n        [[[   6,    5,  -16],\n          [ -22,   81,  -61],\n          [   2,   85,  -81]],\n\n         [[  -4,   20,  -25],\n          [ -16,  127, -108],\n          [   1,  122, -116]],\n\n         [[   6,   -2,   -1],\n          [ -14,   46,  -39],\n          [   0,   46,  -46]]],\n\n\n        [[[   2,   66,   74],\n          [  24,    7,   44],\n          [  11,  -15,   23]],\n\n         [[  36,   49,   28],\n          [  36,   32,   54],\n          [  29,   12,   63]],\n\n         [[ 127,   99,   97],\n          [  71,   69,  118],\n          [  45,   59,   45]]],\n\n\n        [[[ -20,  -63,  -36],\n          [ -86,  -92,  -28],\n          [  12,   -2,  -21]],\n\n         [[  93,  109,  109],\n          [  23,   59,  105],\n          [  97,  127,   74]],\n\n         [[  12,  -56,  -90],\n          [ -90, -123, -108],\n          [ -16,  -27,  -64]]],\n\n\n        [[[ -25,    7,   17],\n          [  15,   33,    0],\n          [ -16,   90,   61]],\n\n         [[   3,   16,   -4],\n          [   9,   46,  -11],\n          [ -27,  127,  116]],\n\n         [[  -1,    0,    1],\n          [  14,   13,   -5],\n          [ -22,   54,   33]]],\n\n\n        [[[ -29,  -57,  -15],\n          [  49,   65,   17],\n          [  -8,   -7,    5]],\n\n         [[ -58, -121,  -40],\n          [  98,  127,   31],\n          [ -21,  -18,   -3]],\n\n         [[ -10,  -21,   -5],\n          [  24,   29,    5],\n          [  -3,   -4,    4]]],\n\n\n        [[[ 104,    7,    4],\n          [  22,  -13,    0],\n          [  10,    1,   -7]],\n\n         [[ 127,   20,   11],\n          [   7,   -9,   13],\n          [  -5,    2,  -11]],\n\n         [[  58,  -15,   -8],\n          [ -27,  -16,    0],\n          [  10,   24,  -10]]],\n\n\n        [[[  81,   30,   66],\n          [  20,  127,    5],\n          [ 103,   66,   86]],\n\n         [[  -4,   36,  -14],\n          [  28,  -14,   -9],\n          [  78,   28,   -9]],\n\n         [[  45,  -12,   -9],\n          [  36,    3,  -18],\n          [  40,   69,  -62]]],\n\n\n        [[[  66,  103,  115],\n          [ 127,   85,   85],\n          [ 114,   20,   56]],\n\n         [[ -43,  -31,  -49],\n          [ -37,    9,   32],\n          [  13,   18,   18]],\n\n         [[  26,  -30,  -18],\n          [  10,   14,    1],\n          [  47,   46,   -7]]],\n\n\n        [[[ -22,  -19,   36],\n          [ -17,   55,   96],\n          [  23,   13,   26]],\n\n         [[ -30,  -28,   48],\n          [ -27,   74,  127],\n          [   5,   13,   20]],\n\n         [[ -16,  -39,   17],\n          [ -25,   32,   86],\n          [  21,   -4,   -3]]],\n\n\n        [[[  16,   32,   29],\n          [ -19,  -57,    3],\n          [ -32,  -34,    4]],\n\n         [[ -66,  -37,  -25],\n          [ -69, -114,   -4],\n          [-102,  -78, -127]],\n\n         [[  40,   11,   10],\n          [  12,  -44,    6],\n          [ -35,  -30,  -14]]],\n\n\n        [[[  30,   -2,  -15],\n          [ -10,    5,   14],\n          [ -26,   44,   95]],\n\n         [[  15,   -9,  -50],\n          [  -4,   59,   14],\n          [ -28,  111,  127]],\n\n         [[   9,    8,  -18],\n          [  -5,   -9,   10],\n          [  -2,   12,   77]]],\n\n\n        [[[   6,  -47,  -61],\n          [ -47, -110, -127],\n          [ -26,  -71,  -81]],\n\n         [[  32,   30,   23],\n          [  24,   17,   10],\n          [  31,   17,    8]],\n\n         [[ -23,   25,   28],\n          [  24,  100,  102],\n          [   5,   60,   53]]],\n\n\n        [[[  -7, -118,   -2],\n          [   2,  -61,   -5],\n          [  29,   26,   38]],\n\n         [[ -77, -127,  -49],\n          [ -35,  -37,  -30],\n          [ -48,    4,  -23]],\n\n         [[  67,  -56,   42],\n          [  16,  -50,   -3],\n          [  -3,    2,    9]]],\n\n\n        [[[ -34,  -21,   60],\n          [  54,  -66,  -10],\n          [ -26,   17,  -20]],\n\n         [[ -30,  -37,  105],\n          [  66, -127,  -14],\n          [ -29,    1,  -33]],\n\n         [[ -24,   -1,   23],\n          [  35,  -36,    7],\n          [ -24,   33,  -23]]],\n\n\n        [[[  15,   41,   35],\n          [  65,   67,   35],\n          [ -29,   -6,   53]],\n\n         [[ -49,  -80,  -59],\n          [ -24,  -85, -107],\n          [ -67, -103,  -63]],\n\n         [[ -18,   54,   64],\n          [  82,  127,   81],\n          [  20,   31,   34]]],\n\n\n        [[[  39,   14,    2],\n          [  22,    7,  -37],\n          [   9,  -61, -100]],\n\n         [[  74,   41,    9],\n          [  96,   55,   24],\n          [  14,   11,  -16]],\n\n         [[  72,   80,   29],\n          [ 127,   45,   -1],\n          [   0,   -2,  -75]]],\n\n\n        [[[  28,   31,    9],\n          [   3,  -25,  -39],\n          [  -7,    8,   45]],\n\n         [[  52,    2,  -67],\n          [  28,  -50,  -92],\n          [  27,   36,   74]],\n\n         [[ -50,  -52, -127],\n          [  -1,  -30,  -82],\n          [ -36,   10,   16]]],\n\n\n        [[[   3,    6,    0],\n          [ -14,   40,   75],\n          [  12,  -43,  -69]],\n\n         [[   6,    9,    5],\n          [ -24,   68,  127],\n          [  21,  -79, -125]],\n\n         [[   7,   -2,    0],\n          [  -8,   20,   36],\n          [   8,  -25,  -29]]],\n\n\n        [[[  -4,   16,  -24],\n          [  14,  -34,  -38],\n          [   1,  -25,  -91]],\n\n         [[  20,    8,   -8],\n          [  22,  -95,  -79],\n          [  47,  -63, -127]],\n\n         [[ -18,   21,   31],\n          [   3,   -3,   -1],\n          [   2,    4,  -61]]],\n\n\n        [[[  32,   10,   -6],\n          [ -39,  -23,   21],\n          [  31,   32,    2]],\n\n         [[  35,  -30,  -29],\n          [-114, -127,  -47],\n          [  37,   24,  -22]],\n\n         [[  17,   12,    2],\n          [ -27,   -1,   17],\n          [  21,   33,   -9]]],\n\n\n        [[[  13,   32,   85],\n          [  47,   42,   72],\n          [  27,  -69,  -33]],\n\n         [[ -16,  -31,  -14],\n          [  27,  -37,   -4],\n          [  59,  -58,   33]],\n\n         [[ -53,  -45,  -57],\n          [ -52, -126, -114],\n          [ -11, -127,  -55]]],\n\n\n        [[[   2,   -7,    2],\n          [  32,  -25,  -53],\n          [  91,  -19,  -96]],\n\n         [[  24,    8,   26],\n          [  29,  -66,  -96],\n          [ 105,  -41, -127]],\n\n         [[   2,   13,   45],\n          [  46,  -10,  -23],\n          [ 100,  -36, -112]]],\n\n\n        [[[ -45,    6,   54],\n          [  42,  120,  127],\n          [  64,   86,   29]],\n\n         [[  -5,  -24,  -23],\n          [ -28,  -53,  -62],\n          [ -33,  -55,  -55]],\n\n         [[  41,   14,  -23],\n          [   0,  -33,  -43],\n          [ -42,  -34,   21]]],\n\n\n        [[[   4,   14,  -10],\n          [ -35,    8,   54],\n          [ -10,   26,   99]],\n\n         [[  15,   15,   -7],\n          [  -3,   32,   81],\n          [  24,   50,  127]],\n\n         [[  -8,  -12,  -60],\n          [ -21,   19,   24],\n          [   3,   33,   61]]]], device='cuda:0', dtype=torch.int8), scale=tensor([[[[2.9407e-04]]],\n\n\n        [[[5.8960e-03]]],\n\n\n        [[[1.1580e-02]]],\n\n\n        [[[5.5220e-03]]],\n\n\n        [[[4.2511e-03]]],\n\n\n        [[[5.3285e-03]]],\n\n\n        [[[7.2222e-03]]],\n\n\n        [[[4.6835e-03]]],\n\n\n        [[[8.5345e-03]]],\n\n\n        [[[4.5279e-05]]],\n\n\n        [[[2.6564e-03]]],\n\n\n        [[[3.5727e-03]]],\n\n\n        [[[5.2667e-03]]],\n\n\n        [[[4.5596e-03]]],\n\n\n        [[[3.0688e-05]]],\n\n\n        [[[3.5445e-05]]],\n\n\n        [[[2.8021e-04]]],\n\n\n        [[[4.7963e-05]]],\n\n\n        [[[2.0221e-03]]],\n\n\n        [[[4.2409e-03]]],\n\n\n        [[[2.8759e-03]]],\n\n\n        [[[4.3914e-03]]],\n\n\n        [[[5.3795e-03]]],\n\n\n        [[[5.0685e-05]]],\n\n\n        [[[2.7667e-03]]],\n\n\n        [[[7.6740e-03]]],\n\n\n        [[[2.7431e-03]]],\n\n\n        [[[6.1529e-03]]],\n\n\n        [[[2.0034e-03]]],\n\n\n        [[[1.5557e-03]]],\n\n\n        [[[6.1699e-03]]],\n\n\n        [[[2.0090e-03]]]], device='cuda:0'), dtype=torch.float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}