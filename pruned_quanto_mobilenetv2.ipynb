{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "9X-j3fR9ytxU",
        "outputId": "7b33859b-c33e-400b-dbd0-bb207ce70ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optimum-quanto in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from optimum-quanto) (2.3.1+cu121)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from optimum-quanto) (1.11.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optimum-quanto) (1.25.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from optimum-quanto) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->optimum-quanto) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->optimum-quanto) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->optimum-quanto) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->optimum-quanto) (1.3.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script>Jupyter.notebook.kernel.restart()</script>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "!pip install optimum-quanto\n",
        "#restart kernal after installing\n",
        "from IPython.core.display import HTML\n",
        "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CerBVQCoytxX",
        "outputId": "a8b141e1-0e59-46bc-e590-c620923bb078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-pruning in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-pruning) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-pruning) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torch-pruning) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-pruning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-pruning) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-pruning\n",
        "import torch_pruning as tp\n",
        "from optimum.quanto import Calibration, QTensor, freeze, qfloat8, qint4, qint8, qint2,quantize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9I7QqBvytxX"
      },
      "outputs": [],
      "source": [
        "def train_model(model,\n",
        "                train_loader,\n",
        "                test_loader,\n",
        "                device,\n",
        "                learning_rate=1e-1,\n",
        "                num_epochs=200):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(),\n",
        "                          lr=learning_rate,\n",
        "                          momentum=0.9,\n",
        "                          weight_decay=1e-4)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                     milestones=[100, 150],\n",
        "                                                     gamma=0.1,\n",
        "                                                     last_epoch=-1)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = evaluate_model(model=model,\n",
        "                                              test_loader=test_loader,\n",
        "                                              device=device,\n",
        "                                              criterion=criterion)\n",
        "    print(\"Epoch: {:03d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(\n",
        "        0, eval_loss, eval_accuracy))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_accuracy = running_corrects / len(train_loader.dataset)\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        eval_loss, eval_accuracy = evaluate_model(model=model,\n",
        "                                                  test_loader=test_loader,\n",
        "                                                  device=device,\n",
        "                                                  criterion=criterion)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(\n",
        "            \"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\"\n",
        "            .format(epoch + 1, train_loss, train_accuracy, eval_loss,\n",
        "                    eval_accuracy))\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, test_loader, device, criterion=None):\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    running_loss = 0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in test_loader:\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        if criterion is not None:\n",
        "            loss = criterion(outputs, labels).item()\n",
        "        else:\n",
        "            loss = 0\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    eval_loss = running_loss / len(test_loader.dataset)\n",
        "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
        "\n",
        "    return eval_loss, eval_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OskFFOfytxY"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_dir, model_filename):\n",
        "\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "    model_filepath = os.path.join(model_dir, model_filename)\n",
        "    torch.save(model.state_dict(), model_filepath)\n",
        "\n",
        "def load_model(model, model_filepath, device):\n",
        "\n",
        "    model.load_state_dict(torch.load(model_filepath, map_location=device))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrwuW06vytxY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Transformation for MobileNet\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale images to 3 channels\n",
        "    transforms.Resize((32, 32)),  # Resize to 224x224 as MobileNet expects this input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # Standard normalization for ImageNet\n",
        "])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzPVrL3UytxZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import time\n",
        "def test(model, device, test_loader):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        start = time.time()\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            if isinstance(output, QTensor):\n",
        "                output = output.dequantize()\n",
        "            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        end = time.time()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print(\n",
        "        \"\\nTest set evaluated in {:.2f} s: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
        "            end - start, test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI77kDEZytxZ",
        "outputId": "af0dabd3-424d-454f-f20d-3290f4215906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Loss: 0.1245\n",
            "Accuracy of the model on the test images: 98.89 %\n"
          ]
        }
      ],
      "source": [
        "# Load pretrained MobileNet model\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "# Modify the classifier to match the number of classes in MNIST (10 classes)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)\n",
        "\n",
        "# Move model to the device (GPU or CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, test_loader, device, criterion, optimizer, num_epochs=1):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "        # Evaluate the model\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f'Accuracy of the model on the test images: {100 * correct / total} %')\n",
        "\n",
        "# Train and evaluate the model\n",
        "train_model(model=model,\n",
        "            train_loader=train_loader,\n",
        "            test_loader=test_loader,\n",
        "            device=device,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            num_epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwfWEjlRx7Di",
        "outputId": "ce18dc24-84f6-4158-a6b1-d0acf5cd59fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0BCFuYjytxZ",
        "outputId": "a4b9dddf-5f9d-4e73-9d7f-dff1f90ff531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set evaluated in 4.97 s: Average loss: -10.9088, Accuracy: 9889/10000 (99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test(model, device, test_loader)\n",
        "\n",
        "model_dir = \"/content/drive/MyDrive/vision lab/\"\n",
        "model_filename = \"Mobilenet_v2.pth\"\n",
        "model_filepath = model_dir + model_filename\n",
        "import os\n",
        "#save_model(model=model, model_dir=model_dir, model_filename=model_filename)\n",
        "torch.save(model,model_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ah85i504ZoC"
      },
      "outputs": [],
      "source": [
        "#new_model = torch.load(model_filepath)\n",
        "#test(new_model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO6GoRR2ytxa",
        "outputId": "4d367891-2273-4076-ff48-bdbb383f03d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "all_images = []\n",
        "targets = []\n",
        "\n",
        "for image, target in test_loader:\n",
        "    all_images.append(image)\n",
        "    targets.append(target)\n",
        "    break\n",
        "# Concatenate all the images into a single tensor\n",
        "all_images_tensor = torch.cat(all_images, dim=0)\n",
        "targets_tensor = torch.cat(all_images, dim=0)\n",
        "print(all_images_tensor.shape)\n",
        "print(targets_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRUJ2Bo68BOd"
      },
      "outputs": [],
      "source": [
        "# for name,m in new_model.named_modules():\n",
        "#     print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e88kk6jWytxa"
      },
      "outputs": [],
      "source": [
        "# example_inputs = torch.randn(1,3,224,224).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "example_inputs = all_images_tensor.clone().detach().requires_grad_(True).to(device)\n",
        "eample_targets = targets_tensor.clone().detach().requires_grad_(True).to(device)\n",
        "\n",
        "# 1. Importance criterion\n",
        "imp = tp.importance.GroupTaylorImportance() # or GroupNormImportance(p=2), GroupHessianImportance(), etc.\n",
        "\n",
        "# 2. Initialize a pruner with the model and the importance criterion\n",
        "ignored_layers = [model.features[1], model.features[2], model.features[3], model.features[4]]\n",
        "for m in model.modules():\n",
        "    if isinstance(m, torch.nn.Linear) and m.out_features == 10:\n",
        "        ignored_layers.append(m) # DO NOT prune the final classifier!\n",
        "\n",
        "# pruning_ratio_dict = {\n",
        "#     model.features[1]: 0.2,\n",
        "#     model.features[3]: 0.3,\n",
        "#     model.features[6]: 0.4,\n",
        "#     model.features[13]: 0.5,\n",
        "#     model.classifier: 0.2, # Example: Pruning 20% of the channels in the classifier\n",
        "# }\n",
        "\n",
        "pruner = tp.pruner.MetaPruner( # We can always choose MetaPruner if sparse training is not required.\n",
        "    model,\n",
        "    example_inputs,\n",
        "    importance=imp,\n",
        "    pruning_ratio=0.1, # remove 50% channels, ResNet18 = {64, 128, 256, 512} => ResNet18_Half = {32, 64, 128, 256}\n",
        "    # pruning_ratio_dict =pruning_ratio_dict , # customized pruning ratios for layers or blocks\n",
        "    ignored_layers=ignored_layers,\n",
        ")\n",
        "\n",
        "# 3. Prune & finetune the model\n",
        "base_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
        "if isinstance(imp, tp.importance.GroupTaylorImportance):\n",
        "    # Taylor expansion requires gradients for importance estimation\n",
        "#     loss = new_model(example_inputs).sum() # A dummy loss, please replace this line with your loss function and data!\n",
        "    loss = criterion(example_inputs,eample_targets)\n",
        "    loss.backward() # before pruner.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFrceArlytxb",
        "outputId": "9be44f89-faab-458a-e1ec-7ad23b1af23f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Params: 2.24 M => 1.83 M\n",
            "\n",
            "Test set evaluated in 4.94 s: Average loss: -4.9945, Accuracy: 9330/10000 (93%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pruner.step()\n",
        "\n",
        "macs, nparams = tp.utils.count_ops_and_params(model.to(device), example_inputs.to(device))\n",
        "print(\n",
        "    \" Params: %.2f M => %.2f M\"\n",
        "    % (base_nparams / 1e6, nparams / 1e6)\n",
        ")\n",
        "\n",
        "test(model, device, test_loader)\n",
        "\n",
        "torch.save(model,\"/content/drive/MyDrive/vision lab/pruned.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMxYVQHnytxb",
        "outputId": "bd9cbe0f-b7b7-42c5-8864-63ec58d685cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibrating ...\n",
            "\n",
            "Test set evaluated in 10.74 s: Average loss: -2.3630, Accuracy: 5735/10000 (57%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def Quantize(model,weights_dtype,activations_dtype):\n",
        "    quantize(model, weights=weights_dtype, activations=activations_dtype)\n",
        "    print(\"Calibrating ...\")\n",
        "    with Calibration():\n",
        "        test(model, device, test_loader)\n",
        "    freeze(model)\n",
        "\n",
        "weights = [qint8,qint4,qint2,qfloat8]\n",
        "strs = [\"int8.pth\",\"int4.pth\",\"int2.pth\",\"float8.pth\"]\n",
        "activations = [qint8,qint4,qint2,qfloat8]\n",
        "\n",
        "i= 1#change here\n",
        "# pruned_model = torch.load(\"/content/drive/MyDrive/vision lab/Mobilenet_v2.pth\")\n",
        "Quantize(model = model,weights_dtype=weights[i],activations_dtype=activations[i])\n",
        "path = \"/content/drive/MyDrive/vision lab/\"+strs[i]\n",
        "torch.save(model,path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRShkgemytxb",
        "outputId": "f404dc29-e3c6-4ebb-a30c-207de6b281ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int4 model:\n",
            "\n",
            "Test set evaluated in 6.71 s: Average loss: -2.3633, Accuracy: 5731/10000 (57%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if i==0:\n",
        "    ptq_model = torch.load(\"/content/drive/MyDrive/vision lab/int8.pth\")\n",
        "    print(\"int8 model:\")\n",
        "    test(ptq_model, device, test_loader)\n",
        "elif i==1:\n",
        "    ptq_model = torch.load(\"/content/drive/MyDrive/vision lab/int4.pth\")\n",
        "    print(\"int4 model:\")\n",
        "    test(ptq_model, device, test_loader)\n",
        "elif i==2:\n",
        "    ptq_model = torch.load(\"/content/drive/MyDrive/vision lab/int2.pth\")\n",
        "    print(\"int2 model:\")\n",
        "#     test(ptq_model, device, test_loader)\n",
        "else:\n",
        "    ptq_model = torch.load(\"/content/drive/MyDrive/vision lab/float8.pth\")\n",
        "    print(\"float8 model:\")\n",
        "    test(ptq_model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEZUX71Wytxc"
      },
      "outputs": [],
      "source": [
        "# for name, param in ptq_model.named_parameters():\n",
        "#     print(name)\n",
        "#     print(param)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ehQ5y51ytxc"
      },
      "source": [
        "# **QAT for model(optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P49GLQdWytxd",
        "outputId": "2cc91a7c-b892-417e-b0ef-6f747a6bfcc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Loss: 2.3026\n",
            "Accuracy of the model on the test images: 9.71 %\n",
            "Epoch [2/2], Loss: 2.3026\n",
            "Accuracy of the model on the test images: 9.65 %\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'to'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-2041c426420c>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             num_epochs=2)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqat_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqat_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-8ee50954629a>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to'"
          ]
        }
      ],
      "source": [
        "quantize(ptq_model,weights=qint4,activations=qint4)\n",
        "qat_model = train_model(model=ptq_model,\n",
        "            train_loader=train_loader,\n",
        "            test_loader=test_loader,\n",
        "            device=device,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            num_epochs=2)\n",
        "\n",
        "test(qat_model, device, test_loader)\n",
        "\n",
        "freeze(qat_model)\n",
        "print(\"after freezing:\")\n",
        "test(qat_model, device, test_loader)\n",
        "torch.save(qat_model,path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gqjJZSuytxd",
        "outputId": "8edec1ae-472b-44e8-dc45-1b4a5648eb52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer1.0.weight\n",
            "QBytesTensor(tensor([[[[  14, -105,  -63,  -20,   52],\n",
            "          [  17,  -59,  -73,  -45,   66],\n",
            "          [  -4,  -74,  -99,  -18,   35],\n",
            "          [  12,  -36,  -84,  -52,   34],\n",
            "          [  49,  -58, -127,  -65,   12]]],\n",
            "\n",
            "\n",
            "        [[[ -19,  -48,   -2,   54,   82],\n",
            "          [  27,  -49,  -95,  -62,    5],\n",
            "          [  61,  -65,  -86,  -88,  -59],\n",
            "          [  88,   41,  -40,  -30,  -49],\n",
            "          [  28,  127,  125,   84,   40]]],\n",
            "\n",
            "\n",
            "        [[[-127,  -82,  -58,  -20,   -3],\n",
            "          [ -41,  -79,  -85,  -89,  -69],\n",
            "          [   7,   14,  -10,  -37,  -73],\n",
            "          [  51,   17,   53,   16,  -11],\n",
            "          [  14,   10,   -8,    7,   29]]],\n",
            "\n",
            "\n",
            "        [[[ -22,  -24,  -54,  -55,   -1],\n",
            "          [ -11,  -84,  -91,  -61,   96],\n",
            "          [-127,  -91,  -24,   26,   95],\n",
            "          [-125,  -33,   35,   74,  104],\n",
            "          [  50,   84,   82,  120,   34]]],\n",
            "\n",
            "\n",
            "        [[[  38,   37,  -53, -104,  -88],\n",
            "          [  36,    8,  -70,  -42,  -69],\n",
            "          [  41,  -22,  -68, -113,   -4],\n",
            "          [  27,  -65,  -82,  -40,  -10],\n",
            "          [  -3, -102, -127,  -21,    0]]],\n",
            "\n",
            "\n",
            "        [[[ 127,   96,  -31,  -66,  -90],\n",
            "          [  53,  104,   20,  -61,  -47],\n",
            "          [  64,  117,   42,  -42,  -30],\n",
            "          [  24,  122,   -3,   27,  -71],\n",
            "          [  15,  107,   13,  -61,  -98]]]], device='cuda:0', dtype=torch.int8), scale=tensor([[[[0.0036]]],\n",
            "\n",
            "\n",
            "        [[[0.0071]]],\n",
            "\n",
            "\n",
            "        [[[0.0050]]],\n",
            "\n",
            "\n",
            "        [[[0.0042]]],\n",
            "\n",
            "\n",
            "        [[[0.0038]]],\n",
            "\n",
            "\n",
            "        [[[0.0040]]]], device='cuda:0'), dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "for name, param in qat_model.named_parameters():\n",
        "    print(name)\n",
        "    print(param)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnRbT8z5ytxd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}