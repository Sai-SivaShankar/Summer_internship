{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install optimum-quanto\n#restart kernal after installing\nfrom IPython.core.display import HTML\nHTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:40:53.550695Z","iopub.execute_input":"2024-07-21T15:40:53.551612Z","iopub.status.idle":"2024-07-21T15:43:24.944709Z","shell.execute_reply.started":"2024-07-21T15:40:53.551567Z","shell.execute_reply":"2024-07-21T15:43:24.943616Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting optimum-quanto\n  Downloading optimum_quanto-0.2.2-py3-none-any.whl.metadata (10 kB)\nCollecting torch>=2.3.0 (from optimum-quanto)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from optimum-quanto) (1.11.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum-quanto) (1.26.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from optimum-quanto) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->optimum-quanto) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->optimum-quanto) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->optimum-quanto) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->optimum-quanto) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->optimum-quanto) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->optimum-quanto) (2024.3.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.1 (from torch>=2.3.0->optimum-quanto)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->optimum-quanto)\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.3.0->optimum-quanto) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.3.0->optimum-quanto) (1.3.0)\nDownloading optimum_quanto-0.2.2-py3-none-any.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, optimum-quanto\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 optimum-quanto-0.2.2 torch-2.3.1 triton-2.3.1\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<script>Jupyter.notebook.kernel.restart()</script>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install torch-pruning \nimport torch_pruning as tp\nfrom optimum.quanto import Calibration, QTensor, freeze, qfloat8, qint4, qint8, qint2,quantize","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:43:24.947455Z","iopub.execute_input":"2024-07-21T15:43:24.947874Z","iopub.status.idle":"2024-07-21T15:43:44.980237Z","shell.execute_reply.started":"2024-07-21T15:43:24.947817Z","shell.execute_reply":"2024-07-21T15:43:44.979399Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting torch-pruning\n  Downloading torch_pruning-1.4.1-py3-none-any.whl.metadata (28 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torch-pruning) (2.3.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-pruning) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (2024.3.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torch-pruning) (12.5.82)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torch-pruning) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torch-pruning) (1.3.0)\nDownloading torch_pruning-1.4.1-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-pruning\nSuccessfully installed torch-pruning-1.4.1\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model(model,\n                train_loader,\n                test_loader,\n                device,\n                learning_rate=1e-1,\n                num_epochs=200):\n\n    criterion = nn.CrossEntropyLoss()\n\n    model.to(device)\n\n    optimizer = optim.SGD(model.parameters(),\n                          lr=learning_rate,\n                          momentum=0.9,\n                          weight_decay=1e-4)\n    \n    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n                                                     milestones=[100, 150],\n                                                     gamma=0.1,\n                                                     last_epoch=-1)\n\n    # Evaluation\n    model.eval()\n    eval_loss, eval_accuracy = evaluate_model(model=model,\n                                              test_loader=test_loader,\n                                              device=device,\n                                              criterion=criterion)\n    print(\"Epoch: {:03d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(\n        0, eval_loss, eval_accuracy))\n\n    for epoch in range(num_epochs):\n\n        # Training\n        model.train()\n\n        running_loss = 0\n        running_corrects = 0\n\n        for inputs, labels in train_loader:\n\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # statistics\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        train_loss = running_loss / len(train_loader.dataset)\n        train_accuracy = running_corrects / len(train_loader.dataset)\n\n        # Evaluation\n        model.eval()\n        eval_loss, eval_accuracy = evaluate_model(model=model,\n                                                  test_loader=test_loader,\n                                                  device=device,\n                                                  criterion=criterion)\n        \n        scheduler.step()\n\n        print(\n            \"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\"\n            .format(epoch + 1, train_loss, train_accuracy, eval_loss,\n                    eval_accuracy))\n\n    return model\n\ndef evaluate_model(model, test_loader, device, criterion=None):\n\n    model.eval()\n    model.to(device)\n\n    running_loss = 0\n    running_corrects = 0\n\n    for inputs, labels in test_loader:\n\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        if criterion is not None:\n            loss = criterion(outputs, labels).item()\n        else:\n            loss = 0\n\n        # statistics\n        running_loss += loss * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\n    eval_loss = running_loss / len(test_loader.dataset)\n    eval_accuracy = running_corrects / len(test_loader.dataset)\n\n    return eval_loss, eval_accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:43:44.981398Z","iopub.execute_input":"2024-07-21T15:43:44.981678Z","iopub.status.idle":"2024-07-21T15:43:44.998163Z","shell.execute_reply.started":"2024-07-21T15:43:44.981652Z","shell.execute_reply":"2024-07-21T15:43:44.997126Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def save_model(model, model_dir, model_filename):\n\n    if not os.path.exists(model_dir):\n        os.makedirs(model_dir)\n    model_filepath = os.path.join(model_dir, model_filename)\n    torch.save(model.state_dict(), model_filepath)\n\ndef load_model(model, model_filepath, device):\n\n    model.load_state_dict(torch.load(model_filepath, map_location=device))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:43:44.999448Z","iopub.execute_input":"2024-07-21T15:43:45.000113Z","iopub.status.idle":"2024-07-21T15:43:45.010766Z","shell.execute_reply.started":"2024-07-21T15:43:45.000076Z","shell.execute_reply":"2024-07-21T15:43:45.009971Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom torch.utils.data import DataLoader\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntransform = transforms.Compose([\n    transforms.Resize((32, 32)),  # Resize to 32x32 as LeNet-5 expects this input size\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\nbatch_size = 256\n# CIFAR-10 dataset\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n\n# Data loaders\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:43:45.013233Z","iopub.execute_input":"2024-07-21T15:43:45.013610Z","iopub.status.idle":"2024-07-21T15:43:48.061709Z","shell.execute_reply.started":"2024-07-21T15:43:45.013584Z","shell.execute_reply":"2024-07-21T15:43:48.060680Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 34405529.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 1017143.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 9791830.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 2530286.73it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn.functional as F\nimport time\ndef test(model, device, test_loader):\n    model.to(device)\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        start = time.time()\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            if isinstance(output, QTensor):\n                output = output.dequantize()\n            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n        end = time.time()\n\n    test_loss /= len(test_loader.dataset)\n\n    print(\n        \"\\nTest set evaluated in {:.2f} s: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n            end - start, test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:43:48.063071Z","iopub.execute_input":"2024-07-21T15:43:48.063385Z","iopub.status.idle":"2024-07-21T15:43:48.073728Z","shell.execute_reply.started":"2024-07-21T15:43:48.063357Z","shell.execute_reply":"2024-07-21T15:43:48.072715Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n#Defining the convolutional neural network\nclass LeNet5(nn.Module):\n    def __init__(self, num_classes):\n        super(LeNet5, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n            nn.BatchNorm2d(6),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.fc = nn.Linear(400, 120)\n        self.relu = nn.ReLU()\n        self.fc1 = nn.Linear(120, 84)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(84, num_classes)\n        \n    def forward(self, x):\n        \n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        out = self.relu(out)\n        out = self.fc1(out)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        return out\n\nmodel = LeNet5(10)\n\nmodel = train_model(model=model,\n                        train_loader=train_loader,\n                        test_loader=test_loader,\n                        device=device,\n                        learning_rate=1e-1,\n                        num_epochs=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:43:48.075202Z","iopub.execute_input":"2024-07-21T15:43:48.075591Z","iopub.status.idle":"2024-07-21T15:44:12.932717Z","shell.execute_reply.started":"2024-07-21T15:43:48.075549Z","shell.execute_reply":"2024-07-21T15:44:12.931697Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch: 000 Eval Loss: 2.310 Eval Acc: 0.075\nEpoch: 001 Train Loss: 0.302 Train Acc: 0.913 Eval Loss: 0.052 Eval Acc: 0.985\n","output_type":"stream"}]},{"cell_type":"code","source":"test(model, device, test_loader)\n\nmodel_dir = \"/kaggle/working/models/\"\nmodel_filename = \"LeNet5.pth\"\nmodel_filepath = model_dir + model_filename\nimport os\nsave_model(model=model, model_dir=model_dir, model_filename=model_filename)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:44:12.933908Z","iopub.execute_input":"2024-07-21T15:44:12.934205Z","iopub.status.idle":"2024-07-21T15:44:15.771531Z","shell.execute_reply.started":"2024-07-21T15:44:12.934178Z","shell.execute_reply":"2024-07-21T15:44:15.770594Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\nTest set evaluated in 2.83 s: Average loss: -11.0638, Accuracy: 9846/10000 (98%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"all_images = []\ntargets = []\n\nfor image, target in test_loader:\n    all_images.append(image)\n    targets.append(target)\n    break\n# Concatenate all the images into a single tensor\nall_images_tensor = torch.cat(all_images, dim=0)\ntargets_tensor = torch.cat(all_images, dim=0)\nprint(all_images_tensor.shape)\nprint(targets_tensor.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:44:15.772747Z","iopub.execute_input":"2024-07-21T15:44:15.773075Z","iopub.status.idle":"2024-07-21T15:44:15.855313Z","shell.execute_reply.started":"2024-07-21T15:44:15.773045Z","shell.execute_reply":"2024-07-21T15:44:15.854229Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"torch.Size([256, 1, 32, 32])\ntorch.Size([256, 1, 32, 32])\n","output_type":"stream"}]},{"cell_type":"code","source":"# example_inputs = torch.randn(1,3,224,224).to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\nexample_inputs = all_images_tensor.clone().detach().requires_grad_(True).to(device)\neample_targets = targets_tensor.clone().detach().requires_grad_(True).to(device)\n\n# 1. Importance criterion\nimp = tp.importance.GroupTaylorImportance() # or GroupNormImportance(p=2), GroupHessianImportance(), etc.\n\n# 2. Initialize a pruner with the model and the importance criterion\nignored_layers = []\nfor m in model.modules():\n    if isinstance(m, torch.nn.Linear) and m.out_features == 10:\n        ignored_layers.append(m) # DO NOT prune the final classifier!\n\npruner = tp.pruner.MetaPruner( # We can always choose MetaPruner if sparse training is not required.\n    model,\n    example_inputs,\n    importance=imp,\n    #pruning_ratio=0.5, # remove 50% channels, ResNet18 = {64, 128, 256, 512} => ResNet18_Half = {32, 64, 128, 256}\n    pruning_ratio_dict = {model.layer1: 0, model.layer2: 0.5,model.fc: 0.2,model.fc1: 0.6}, # customized pruning ratios for layers or blocks\n    ignored_layers=ignored_layers,\n)\n\n# 3. Prune & finetune the model\nbase_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\nif isinstance(imp, tp.importance.GroupTaylorImportance):\n    # Taylor expansion requires gradients for importance estimation\n#     loss = model(example_inputs).sum() # A dummy loss, please replace this line with your loss function and data!\n    loss = criterion(example_inputs,eample_targets)\n    loss.backward() # before pruner.step()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:44:15.856712Z","iopub.execute_input":"2024-07-21T15:44:15.857143Z","iopub.status.idle":"2024-07-21T15:44:15.905824Z","shell.execute_reply.started":"2024-07-21T15:44:15.857105Z","shell.execute_reply":"2024-07-21T15:44:15.904740Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"pruner.step()\n\nmacs, nparams = tp.utils.count_ops_and_params(model.to(device), example_inputs.to(device))\nprint(\n    \" Params: %.2f M => %.2f M\"\n    % (base_nparams / 1e6, nparams / 1e6)\n)\n\ntest(model, device, test_loader)\n\ntorch.save(model,\"/kaggle/working/models/pruned.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:44:16.334106Z","iopub.execute_input":"2024-07-21T15:44:16.334539Z","iopub.status.idle":"2024-07-21T15:44:19.457433Z","shell.execute_reply.started":"2024-07-21T15:44:16.334499Z","shell.execute_reply":"2024-07-21T15:44:19.456400Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":" Params: 0.06 M => 0.02 M\n\nTest set evaluated in 2.91 s: Average loss: -6.5733, Accuracy: 9259/10000 (93%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def Quantize(model,weights_dtype,activations_dtype):\n    quantize(model, weights=weights_dtype, activations=activations_dtype)\n    print(\"Calibrating ...\")\n    with Calibration():\n        test(model, device, test_loader)\n    freeze(model)\n\nweights = [qint8,qint4,qint2,qfloat8]\nstrs = [\"int8.pth\",\"int4.pth\",\"int2.pth\",\"float8.pth\"]\nactivations = [qint8,qint4,qint2,qfloat8]\n\ni= 0 #change here\npruned_model = torch.load(\"/kaggle/working/models/pruned.pth\")\nQuantize(model = pruned_model,weights_dtype=weights[i],activations_dtype=activations[i])\npath = \"/kaggle/working/models/\"+strs[i]\ntorch.save(model,path)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:45:41.465860Z","iopub.execute_input":"2024-07-21T15:45:41.466711Z","iopub.status.idle":"2024-07-21T15:45:46.098722Z","shell.execute_reply.started":"2024-07-21T15:45:41.466674Z","shell.execute_reply":"2024-07-21T15:45:46.097614Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Calibrating ...\n\nTest set evaluated in 4.61 s: Average loss: -6.5475, Accuracy: 9255/10000 (93%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"if i==0:\n    ptq_model = torch.load(\"/kaggle/working/models/int8.pth\")\n    print(\"int8 model:\")\n    test(ptq_model, device, test_loader)\nelif i==1:\n    ptq_model = torch.load(\"/kaggle/working/models/int4.pth\")\n    print(\"int4 model:\")\n    test(ptq_model, device, test_loader)\nelif i==2:\n    ptq_model = torch.load(\"/kaggle/working/models/int2.pth\")\n    print(\"int2 model:\")\n#     test(ptq_model, device, test_loader)\nelse:\n    ptq_model = torch.load(\"/kaggle/working/models/float8.pth\")\n    print(\"float8 model:\")\n    test(ptq_model, device, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:45:52.789957Z","iopub.execute_input":"2024-07-21T15:45:52.790580Z","iopub.status.idle":"2024-07-21T15:45:55.664102Z","shell.execute_reply.started":"2024-07-21T15:45:52.790548Z","shell.execute_reply":"2024-07-21T15:45:55.663132Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"int8 model:\n\nTest set evaluated in 2.86 s: Average loss: -6.5733, Accuracy: 9259/10000 (93%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# for name, param in ptq_model.named_parameters():\n#     print(name)\n#     print(param)\n#     break","metadata":{"execution":{"iopub.status.busy":"2024-07-21T12:24:48.875587Z","iopub.status.idle":"2024-07-21T12:24:48.875902Z","shell.execute_reply.started":"2024-07-21T12:24:48.875744Z","shell.execute_reply":"2024-07-21T12:24:48.875757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **QAT for model(optional)**","metadata":{}},{"cell_type":"code","source":"quantize(ptq_model,weights=qint8,activations=qint8)\nqat_model = train_model(model=ptq_model,\n                        train_loader=train_loader,\n                        test_loader=test_loader,\n                        device=device,\n                        learning_rate=1e-1,\n                        num_epochs=3)\n\ntest(qat_model, device, test_loader)\n\nfreeze(qat_model)\nprint(\"after freezing:\")\ntest(qat_model, device, test_loader)\ntorch.save(qat_model,path)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:45:58.150268Z","iopub.execute_input":"2024-07-21T15:45:58.151095Z","iopub.status.idle":"2024-07-21T15:47:19.213162Z","shell.execute_reply.started":"2024-07-21T15:45:58.151063Z","shell.execute_reply":"2024-07-21T15:47:19.212232Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch: 000 Eval Loss: 0.778 Eval Acc: 0.777\nEpoch: 001 Train Loss: 0.098 Train Acc: 0.970 Eval Loss: 0.062 Eval Acc: 0.979\nEpoch: 002 Train Loss: 0.066 Train Acc: 0.979 Eval Loss: 0.056 Eval Acc: 0.982\nEpoch: 003 Train Loss: 0.060 Train Acc: 0.981 Eval Loss: 0.072 Eval Acc: 0.977\n\nTest set evaluated in 3.14 s: Average loss: -13.2942, Accuracy: 9771/10000 (98%)\n\nafter freezing:\n\nTest set evaluated in 3.08 s: Average loss: -13.2942, Accuracy: 9771/10000 (98%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"for name, param in qat_model.named_parameters():\n    print(name)\n    print(param)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:47:19.214731Z","iopub.execute_input":"2024-07-21T15:47:19.215769Z","iopub.status.idle":"2024-07-21T15:47:19.258554Z","shell.execute_reply.started":"2024-07-21T15:47:19.215733Z","shell.execute_reply":"2024-07-21T15:47:19.257593Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"layer1.0.weight\nQBytesTensor(tensor([[[[  14, -105,  -63,  -20,   52],\n          [  17,  -59,  -73,  -45,   66],\n          [  -4,  -74,  -99,  -18,   35],\n          [  12,  -36,  -84,  -52,   34],\n          [  49,  -58, -127,  -65,   12]]],\n\n\n        [[[ -19,  -48,   -2,   54,   82],\n          [  27,  -49,  -95,  -62,    5],\n          [  61,  -65,  -86,  -88,  -59],\n          [  88,   41,  -40,  -30,  -49],\n          [  28,  127,  125,   84,   40]]],\n\n\n        [[[-127,  -82,  -58,  -20,   -3],\n          [ -41,  -79,  -85,  -89,  -69],\n          [   7,   14,  -10,  -37,  -73],\n          [  51,   17,   53,   16,  -11],\n          [  14,   10,   -8,    7,   29]]],\n\n\n        [[[ -22,  -24,  -54,  -55,   -1],\n          [ -11,  -84,  -91,  -61,   96],\n          [-127,  -91,  -24,   26,   95],\n          [-125,  -33,   35,   74,  104],\n          [  50,   84,   82,  120,   34]]],\n\n\n        [[[  38,   37,  -53, -104,  -88],\n          [  36,    8,  -70,  -42,  -69],\n          [  41,  -22,  -68, -113,   -4],\n          [  27,  -65,  -82,  -40,  -10],\n          [  -3, -102, -127,  -21,    0]]],\n\n\n        [[[ 127,   96,  -31,  -66,  -90],\n          [  53,  104,   20,  -61,  -47],\n          [  64,  117,   42,  -42,  -30],\n          [  24,  122,   -3,   27,  -71],\n          [  15,  107,   13,  -61,  -98]]]], device='cuda:0', dtype=torch.int8), scale=tensor([[[[0.0036]]],\n\n\n        [[[0.0071]]],\n\n\n        [[[0.0050]]],\n\n\n        [[[0.0042]]],\n\n\n        [[[0.0038]]],\n\n\n        [[[0.0040]]]], device='cuda:0'), dtype=torch.float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}